{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"HtHAw-DuLICB"},"source":["# Initializing"]},{"cell_type":"code","metadata":{"id":"sMuHzhYmn6mQ"},"source":["# import glob\n","from google.colab import drive\n","# drive.mount('/content/gdrive')\n","# %cd /content/gdrive/MyDrive/Colaboratory/turkish-nlp/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NRbonyfxsd7R"},"source":["!pip install nltk\n","!pip install -U textblob \n","!python -m textblob.download_corpora\n","!pip install nltk\n","!pip install openpyxl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zAOYUwz-siiz"},"source":["from nltk import word_tokenize \n","from textblob import TextBlob\n","import sys\n","import pandas as pd\n","import xlwt\n","\n","from collections import Counter\n","import csv\n","from nltk.corpus import stopwords\n","from numpy import loadtxt\n","from nltk.util import ngrams\n","import nltk, re, string, collections\n","nltk.download('stopwords')\n","\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xsxwaA-Ak0GF"},"source":["def readFile(fileName):\n","  file = open(fileName, \"r\")\n","  words = file.read()\n","  file.close\n","  return words  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OonOwz0y-V-n"},"source":["# Filtering"]},{"cell_type":"code","metadata":{"id":"iAAi_s2W-PjJ"},"source":["for x in [\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\"]:\n","\n","  # appendFile = open('filtered.txt','a+')\n","\n","  path = \"filtered-corpus/filtered-donem\" + x + \".txt\"\n","  all_files = glob.glob(path)\n","  words = \"\"\n","  \n","  # appendFile = open('filtered-corpus/filtered-donem' + x + '.txt','a+')\n","\n","  for file in all_files:\n","    words = words + readFile(file)\n","  \n","  tokenized = [idx.lower() for idx in words.split() if re.findall(\"^[a-zA-ZğüşöçİĞÜŞÖÇ]+$\", idx) and len(idx) > 1]\n","\n","  # for idx in tokenized:\n","  #   appendFile.write(\" \"+idx.lower())\n","  \n","  # appendFile.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bVsqtBbjMGgO"},"source":["# n-grams"]},{"cell_type":"code","metadata":{"id":"Z6ea6VfY1z4-"},"source":["for x in [\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\"]:\n","\n","  path = \"corpus/donem\" + x + \"/yıl*/*.txt\"\n","  all_files = glob.glob(path)\n","  words = \"\"\n","  \n","  for file in all_files:\n","    words = words + readFile(file)\n","  \n","  tokenized = [idx.lower() for idx in words.split() if re.findall(\"^[a-zA-Z0-9ğüşöçİĞÜŞÖÇ]+$\", idx) and len(idx) > 1]\n","\n","  unigrams = ngrams(tokenized, 1)\n","  unigramsFreq = collections.Counter(unigrams)\n","  df = pd.DataFrame(unigramsFreq.most_common(1000), columns = ['Words', 'Score'])\n","  df = df.sort_values(by='Score', ascending=False)\n","  p = '.results-corpus/without-stopwords/unigrams/unigram'+ x +'.csv'\n","  df.to_csv(p, index = True, header=True)\n","\n","  bigrams = ngrams(tokenized, 2)\n","  bigramsFreq = collections.Counter(bigrams)\n","  df = pd.DataFrame(bigramsFreq.most_common(1000), columns = ['Words', 'Score'])\n","  df = df.sort_values(by='Score', ascending=False)\n","  p = '.results-corpus/without-stopwords/bigrams/bigram'+ x +'.csv'\n","  df.to_csv(p, index = True, header=True)\n","\n","  trigrams = ngrams(tokenized, 3)\n","  trigramsFreq = collections.Counter(trigrams)\n","  df = pd.DataFrame(trigramsFreq.most_common(1000), columns = ['Words', 'Score'])\n","  df = df.sort_values(by='Score', ascending=False)\n","  p = '.results-corpus/without-stopwords/trigrams/trigram'+ x +'.csv'\n","  df.to_csv(p, index = True, header=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SBq8SN-VAYPo"},"source":["# Collocations"]},{"cell_type":"code","metadata":{"id":"zzEm12VYKzJZ"},"source":["corpus = readFile('filtered-corpus/all-corpus-for-collacations.txt')\n","\n","tokenized = [idx.lower() for idx in corpus.split()]\n","# tokenized = [item for items in corpus for item in items]\n","\n","bigrams = nltk.collocations.BigramAssocMeasures()\n","trigrams = nltk.collocations.TrigramAssocMeasures()\n","\n","bigramFinder = nltk.collocations.BigramCollocationFinder.from_words(tokenized)\n","trigramFinder = nltk.collocations.TrigramCollocationFinder.from_words(tokenized)\n","\n","bigramFinder.apply_freq_filter(30)\n","trigramFinder.apply_freq_filter(30)\n","\n","bigram_freq = bigramFinder.ngram_fd.items()\n","bigramFreqTable = pd.DataFrame(list(bigram_freq), columns=['bigram','freq']).sort_values(by='freq', ascending=False)\n","# bigramFreqTable[:10]\n","\n","trigram_freq = trigramFinder.ngram_fd.items()\n","trigramFreqTable = pd.DataFrame(list(trigram_freq), columns=['trigram','freq']).sort_values(by='freq', ascending=False)\n","# trigramFreqTable[:10] "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YigeU8S1menm"},"source":["# PMI\n","\n","bigramPMITable = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.pmi)), columns=['bigram','PMI']).sort_values(by='PMI', ascending=False)\n","# bigramPMITable[:10]\n","p = 'collacations-results/all-corpus-bigram-pmi.csv'\n","bigramPMITable[:100].to_csv(p, index = True, header=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p7cCVtgY37vi"},"source":["trigramPMITable = pd.DataFrame(list(trigramFinder.score_ngrams(trigrams.pmi)), columns=['trigram','PMI']).sort_values(by='PMI', ascending=False)\n","# trigramPMITable[:10]\n","p = 'collacations-results/all-corpus-trigram-pmi.csv'\n","trigramPMITable[:100].to_csv(p, index = True, header=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-uxGPYojmhyg"},"source":["# t-test\n","\n","bigramTtable = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.student_t)), columns=['bigram','t']).sort_values(by='t', ascending=False)\n","# bigramTtable[:10]\n","p = 'collacations-results/all-corpus-bigram-t-test.csv'\n","bigramTtable[:100].to_csv(p, index = True, header=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HGoxUDHd39j2"},"source":["trigramTtable = pd.DataFrame(list(trigramFinder.score_ngrams(trigrams.student_t)), columns=['trigram','t']).sort_values(by='t', ascending=False)\n","# trigramTtable[:10]\n","p = 'collacations-results/all-corpus-trigram-t-test.csv'\n","trigramTtable[:100].to_csv(p, index = True, header=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gA5pPq-YoNX5"},"source":["# Chi-Square\n","\n","bigramChiTable = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.chi_sq)), columns=['bigram','chi-sq']).sort_values(by='chi-sq', ascending=False)\n","# bigramChiTable[:10]\n","p = 'collacations-results/all-corpus-bigram-chi.csv'\n","bigramChiTable[:100].to_csv(p, index = True, header=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_IKOYsdb4AUA"},"source":["trigramChiTable = pd.DataFrame(list(trigramFinder.score_ngrams(trigrams.chi_sq)), columns=['trigram','chi-sq']).sort_values(by='chi-sq', ascending=False)\n","# trigramChiTable[:10]\n","p = 'collacations-results/all-corpus-trigram-chi.csv'\n","trigramChiTable[:100].to_csv(p, index = True, header=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_I4KBDivoFvk"},"source":["#comparison\n","\n","freq_bi = bigramFreqTable[:15].bigram.values\n","freq_tri = trigramFreqTable[:15].trigram.values\n","\n","pmi_bi = bigramPMITable[:15].bigram.values\n","pmi_tri = trigramPMITable[:15].trigram.values\n","\n","t_bi = bigramTtable[:15].bigram.values\n","t_tri = trigramTtable[:15].trigram.values\n","\n","chi_bi = bigramChiTable[:15].bigram.values\n","chi_tri = trigramChiTable[:15].trigram.values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KQVNDkz0oCiT"},"source":["bigramsCompare = pd.DataFrame([freq_bi, pmi_bi, t_bi, chi_bi]).T\n","bigramsCompare.columns = ['Frequency', 'PMI', 't-test', 'Chi-Sq Test']\n","# bigramsCompare\n","p = 'collacations-results/all-corpus-bigram-compare.csv'\n","bigramsCompare[:100].to_csv(p, index = True, header=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WR1KYYwxsPSB"},"source":["trigramsCompare = pd.DataFrame([freq_tri, pmi_tri, t_tri, chi_tri]).T\n","trigramsCompare.columns = ['Frequency', 'PMI', 't-test', 'Chi-Sq Test']\n","# trigramsCompare\n","p = 'collacations-results/all-corpus-trigram-compare.csv'\n","trigramsCompare[:100].to_csv(p, index = True, header=True)"],"execution_count":null,"outputs":[]}]}